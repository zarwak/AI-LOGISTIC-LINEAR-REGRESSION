import pandas as pd
import numpy as np

# Step 1: Implement Gradient Descent for two features
def gradient_descent(X1, X2, Y, learning_rate=0.01, epochs=1000):
    n = len(Y)
    theta_0 = theta_1 = theta_2 = 0  # Initialize all parameters to 0

    for _ in range(epochs):
        Y_pred = theta_0 + theta_1 * X1 + theta_2 * X2  # Prediction
        error = Y_pred - Y

        # Compute gradients
        d_theta_0 = (2/n) * np.sum(error)
        d_theta_1 = (2/n) * np.sum(error * X1)
        d_theta_2 = (2/n) * np.sum(error * X2)

        # Update parameters
        theta_0 -= learning_rate * d_theta_0
        theta_1 -= learning_rate * d_theta_1
        theta_2 -= learning_rate * d_theta_2

    return theta_0, theta_1, theta_2

# Step 2: Predict using the learned parameters
def predict(X1, X2, theta_0, theta_1, theta_2):
    return theta_0 + theta_1 * X1 + theta_2 * X2

# Step 3: Calculate Mean Squared Error
def calculate_mse(Y, Y_pred):
    return np.mean((Y - Y_pred) ** 2)

# Step 4: Main Execution
def main():
    # Load dataset
    df = pd.read_csv('housing.csv')
    X1 = df['area']
    X2 = df['bedrooms']
    Y = df['price']

    # Min-Max Scaling
    X1_scaled = (X1 - X1.min()) / (X1.max() - X1.min())
    X2_scaled = (X2 - X2.min()) / (X2.max() - X2.min())

    # Gradient Descent
    theta_0, theta_1, theta_2 = gradient_descent(X1_scaled, X2_scaled, Y)

    # Predictions
    Y_pred = predict(X1_scaled, X2_scaled, theta_0, theta_1, theta_2)

    # Evaluate performance
    mse = calculate_mse(Y, Y_pred)

    # Output
    print("Learned Parameters:")
    print(f"theta_0 (bias): {theta_0}")
    print(f"theta_1 (area): {theta_1}")
    print(f"theta_2 (bedrooms): {theta_2}")
    print("Mean Squared Error:", mse)

main()
